---
layout: post
title: Unit 7 Introduction to Artificial Neural Networks (ANNs)
subtitle: Perceptron Activities
categories: Module3
tags: [Perceptron Activities, Machine Learning]
---
<html lang="en">
    <table>
    <tr>
   <td> <a href="../../../../MachineLearning" target="_blank" class="button large">Github</a></td> 
    </tr>
</table>

<body>

<h1>Perceptron</h1>

<p>Perceptron is a simple artificial neuron that helps machines make decisions. It is a binary classifier (used for supervised learning) that decides whether something belongs to one category or another. The first neural network model, Perceptron, was designed in 1958. Perceptron learning combines two concepts: the McCulloch-Pitts model of an artificial neuron and the Hebbian learning rule of adjusted weights.</p>

<h2>Applications of Perceptron</h2>
<p>Perceptrons are mainly used in:</p>
<ul>
    <li><strong>Image Recognition</strong></li>
    <li><strong>Data Compression and Encryption</strong></li>
    <li><strong>User Profiling</strong></li>
    <li><strong>Customer Ranking</strong></li>
</ul>

<h2>Types of Perceptron</h2>

<h3>Single Layer Perceptron</h3>
![Perceptron Diagram](../../assets/images/banners/The-architecture-of-single-layer-perceptron.png)
<p>Image Source: <a href="https://commons.wikimedia.org/wiki/File:Single_layer_neural_network.png" target="_blank">Wikimedia Commons</a></p>

<h3>Multi-Layer Perceptron</h3>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/MultilayerNeuralNetworkBigger_english.png/600px-MultilayerNeuralNetworkBigger_english.png" alt="Multi-Layer Perceptron" width="500">
<p>Image Source: <a href="https://commons.wikimedia.org/wiki/File:MultilayerNeuralNetworkBigger_english.png" target="_blank">Wikimedia Commons</a></p>

<p>Check out the GitHub link below for more details. The simple perceptron produces outputs of either 0 or 1. A single-layer perceptron (without hidden layers) was trained to perform binary classification for the AND operation. In contrast, a multi-layer perceptron, utilizing a hidden layer and sigmoid activation function, was used to solve the XOR problem.</p>

</body>
</html>



<table>
    <tr>
  <td> <a href="../../../../MachineLearning" target="_blank" class="button large">Github</a></td> 
    </tr>
</table>
